# Redis
 5-7-9大纲
9大课题 30s-2M/题  5-10题/课
 
JVM
THREAD LOCK
COLLECTION

MQ
REDIS
MYSQL
TRACTIONAL
SPRING SPRINGBOOT
SPRINGCLOUD DUBBO
DOCKER K8S 
 
Redis问题汇总
- 为什么使用redis，解决了什么问题，带来了哪些问题
- redis支持哪些数据类型，及使用场景
- redis单线程为什么快
- redis的内存淘汰策略，key的过期策略
- redis和数据库双写一致性
- redsi缓存穿透、击穿、雪崩
- 缓存预热
- redis热点key并发竞争
- redis持久化
- redis分布式锁
- redis集群方案

### 一、为什么使用Redis，解决了什么问题，又带来了什么问题？不使用可以嘛？
> Redis本身是高性能的，支持高并发场景。

```markdown
解决了什么问题：
① Redis的高性能和高并发特性，可以做MySQL的前置缓存，快速响应。支撑更多的并发
② Redis可以支持分布式锁的实现
带来的问题：
① 缓存双写数据一致性问题
② 缓存穿透问题
③ 缓存击穿问题
④ 缓存雪崩
⑤ 热点key缓存并发竞争问题
⑥ 提高系统复杂度

不使用：
① 请求直接落数据库，不能支持很大的请求量
② 对于很多重复性的请求不能利用缓存加速，浪费服务器资源去重新计算
```

-----

### 二、 Redis支持的数据类型，及使用场景
> Redis支持5种数据类型：String hash list set zset

```markdown
① String：最常用的,value可以是字符或数字
② hash：  value存放结构化的对象，如单点登录用户的信息
③ list:   可以基于list做FIFO队列。利用lrang实现redis分页功能
④ set:    存放不重复的数据,做全局去重
⑤ zset:   多score参数，集合中的元素可以按score排序。可做排行榜，取TOP N操作

```

-----

### 三、单线程的redis为什么这么快
> 

```markdown
1. 纯内存操作，没有磁盘IO
2. 单线程操作，避免了频繁的上下文切换
3. 采用了非阻塞的I/O多路复用机制
```



### 四、Redis 过期策略，内存淘汰机制(内存已满等问题的解决方案)
> 变种问题：Redis只能存10G数据，但现在有20G数据要存。数据设置了过期时间，但到期了内存占用率还很高。
  Redis采用 定期删除+惰性删除策略
  
```markdown
1. Redis的KEY淘汰策略？为何执行了删除KEY但内存占用并没有减少？
D:
定时删除 + 惰性淘汰
定时删除 ：Redis在设置Key的时候创建一个定时器。在达到过期时间时，由定时器删除Key
惰性删除 ：数据达到过期时间不做处理。Redis会在每次请求查询缓存数据时，判断这个key是否过期，如果过期则删除。否则返回value
定期删除 ：Redis默认100ms轮询设置了超时时间的Key。采取随机抽取的策略判断key是否超时。如果超时则删除

优缺点：
定时删除：节约内存，但不分时段占用CPU资源。用时间换空间
惰性删除：严重占用内存，延迟执行，CPU利用率高。用空间换时间
定时删除：内存定期随机清理，占用CPU资源可控。随机抽查、重点抽查

2. 如果REDIS内存已满，内存淘汰机制是？(redis 3.0版本)
D: 
REDIS使用内存存储数据，每次执行前会调用freeMemoryIfNeeded()检测内存是否充足。若不满足，则要删除一些老数据清空存储空间

如果REDIS内存已满，新插入数据时要淘汰已有的部分数据。淘汰的策略有：
情况一：设置了过期时间的key
VOLATILE
① LRU: 从设置了过期时间的数据中，淘汰最近最少使用的数据
② TTL: 从设置了过期时间的数据中挑选将要过期的数据，TTL值越小的越优先被淘汰
③ RANDOM：从设置了过期时间的数据中，任意选择数据进行淘汰
情况二：没有设置过期时间的key
ALLKEYS
④ LRU: 从所有数据中，淘汰最近最少使用的数据
⑤ TTL: 从所有数据中，任意选择数据淘汰
⑥ NO-ENVICTION: 禁止淘汰数据。当内存不足时，写入操作会报错。
系统默认淘汰策略：NO-ENVICTION，可以保证数据不丢失

3. 影响数据淘汰的相关参数配置？
D:
maxmemory  最大可用内存(占用物理内存的比例)；默认为 0 ，生产通常设置在50%以上
maxmemory-samples  每次选取待删除的个数(选取数据时并不会扫描全库，导致严重影响性能。采用随机获取数据的方式作为待检测的删除数据)
maxmemory-policy volatile-lru  删除策略(达到最大可用内存后，对被挑选出来的数据删除的策略)

4. 使用场景
D:
① 如果Redis只做缓存，则可以使用ALLKEYS下的淘汰策略。客户端写缓存时不必携带过期时间
② 如果想使用Redis的持久化功能，则可以使用VOLATILE下的淘汰策略。可以保证没有设置过期时间的key，不会被算法淘汰。

```

-----

### 五、Redis缓存数据库双写一致性
> 在使用Redis中，一般都会涉及到缓存和数据库双写的情况，这时就要考虑缓存和数据库的一致性问题 
  这里针对不同的方案，指出问题并给出解决方案。
  同时排除依赖缓存过期来达到数据一致性的方案。
  
```markdown
1. 先更新缓存，在更新数据库。
2. 先更新数据库，在更新缓存。
3. 先删除缓存，在更新数据库。
4. 先更新数据库，在删除缓存。

方案分析：
1. 先更新缓存，在更新数据库。
   并发线程A写、B写
① 线程A发起写操作，更新缓存
② 线程B发起写操作，更新缓存
③ 线程B更新数据库
④ 线程A更新数据库

结果：数据库最新数据是线程A更新的值，但缓存中保存的是线程B的值。数据不一致。
异常：缓存更新成功了，但数据库更新失败。导致数据不一致。
结论：不使用

2. 先更新数据库，在更新缓存。
   并发线程A写、B写
① 线程A发起写操作，更新数据库
② 线程B发起写操作，更新数据库
③ 线程B更新缓存(由于网络等原因线程B比A早更新了缓存)
④ 线程A更新缓存

结果：数据库最新数据是线程B更新的值，但缓存中保存的是线程A的值。数据不一致。
     业务中写入数据库的值，并不是写入缓存的值。缓存是经过一系列复杂计算后写入的，每次更新缓存但有可能使用并不频繁。会导致性能浪费
     如果是一个写多读少的场景，这种方案会导致数据压根还没读到，缓存就被频繁更新。
异常：数据库更新成功了，但缓存更新失败。导致数据不一致。
结论：不使用

3. 先删除缓存，在更新数据库。 ★★
   并发线程A写、B读
① 线程A发起写操作，删除缓存
② 线程B发起读操作，缓存没命中，去查询数据库获取old值
③ 线程B更新缓存为old值
④ 线程A更新数据库，数据库为new值

结果：数据库最新数据是线程A更新的new值，但缓存中保存的是线程B查询的old值。数据不一致。
异常：如果使用【优化方案a】第二次删除缓存失败，则还是会导致数据不一致。
优化方案：
a.先删除缓存，更新数据库成功后。休眠几百毫秒后，再次删除缓存。
  问题：会造成短暂的数据不一致；要评估好休眠时间；同步休眠会造成吞吐量下降；可改异步休眠删除
b.写请求先修改缓存为【固定值】，更新数据库成功后在更新缓存。读请求先读缓存。判断【固定值】后进入循环状态，等待写请求更新缓存。循环超时则直接去查询数据库更新缓存。
  问题：保证了一致性，但会降低吞吐量。、
c.读写分离：读请求只访问缓存，写请求更新数据数据库和缓存。写请求更新数据库和缓存是事务性动作：如果更新数据库成功，更新缓存失败。则回滚数据库，保证缓存与数据库强一致。
  采用读写分离方案：不仅提高了读的响应速度，由写请求负责数据一致性，只有写成功才会影响缓存数据，时效性大大增强。
d.维护一个JVM内存队列，把对同一个key的更新和查询放入一个队列中，通过串行化的方式保证，读请求在写请求之后执行。实践比较复杂    
结论：这种方案一般可以满足上万的并发操作。但如果不做优化，达到上亿并发时会出现缓存不一致问题。通过优化方案a、b可以解决问题，但还需要进一步优化。解决删除失败问题

4. 先更新数据库，在删除缓存。  ★★★
   并发线程A写、B读
① 线程A发起写操作，更新数据库
② 线程B发起读操作，缓存没命中，去查询数据库获取old值
③ 线程A删除缓存
④ 线程B更新缓存为old值

结果：实际发生这种情况的概率非常小。因为线程A写入的时间一般是要大于线程B查询的时间，所以线程B更新缓存的操作会早与线程A删除缓存的操作。
     实际情况中，发生上述情况的概率几乎没有。也可以通过异步延时删除策略来保证万一。
异常：异步延时第二次删除缓存失败，则还是会导致数据不一致。
优化方案：提供一个保障的重试机制
a. 如果删除缓存失败。则将要删除的key发送至指定的MQ队列，自己通过监听队列，获取要删除的key进行删除操作，失败进行重试。(对业务代码有入侵)
b. 启动一个订阅程序去订阅数据库binlog，获取需要操作的key，进行删除缓存操作。删除失败则进入MQ队列，进行重试 
结论：推荐使用。Facebook也在使用这种方案，极端情况下会出现不一致。

```      

> 参考文档

[如何保证缓存与数据库的双写一致性](https://www.cnblogs.com/williamjie/p/11287317.html)

[Redis使用总结（二、缓存和数据库双写一致性问题）](https://blog.csdn.net/hukaijun/article/details/81010475)

[如何保证缓存与数据库的双写一致性](https://github.com/shishan100/Java-Interview-Advanced/blob/master/docs/high-concurrency/redis-consistence.md)

[并发环境下，先操作数据库还是先操作缓存？](https://juejin.im/post/6844903907726983181#heading-3)

[先更新缓存还是先更新数据库](https://www.cnblogs.com/mrcharleshu/p/13196386.html)

[更新缓存](https://www.cnblogs.com/cjsblog/p/10752245.html)

-----

### 六、缓存击穿、缓存穿透、缓存雪崩
> 

```markdown
1. 缓存穿透：数据在缓存和数据库中都不存在，用户或黑客不断发起请求，导致所有请求都会落到DB。
解决方案：
① 缓存空值，设置较短的过期时间。(方案pass: 大量攻击会导致内存变大，同时基于内存淘汰策略会淘汰真正的业务缓存数据)
② 提供一个有效的拦截机制。如：布隆过滤器，或内部维护一系列合法有效的key，迅速判断请求key是否合法。不合法则直接返回
③ 在接口层用户登录状态、权限，参数校验等。同时可以配合限流熔断机制，防止数据库被打死
④ 采用分布式锁，获取锁的请求去查询数据库更新缓存，没获取锁的休眠一段时间重试

2. 缓存击穿：某个热点KEY在被高并发访问时失效，导致所有请求击穿缓存落到DB。
解决方案：
① 热点数据设置缓存永不过期
② 基于分布式锁实现互斥，如果缓存过期则加锁去查询数据库构建缓存。等第一个请求构建完缓存后，释放锁。
③ 控制锁的粒度为：针对某KEY加锁，而不是整段逻辑。


3. 缓存雪崩：在同一时间大量缓存集体过期失效，而此时有大量请求过来，则请求会直接落到DB。严重会引起DB down机。
            Redis服务器宕机，不可用。导致请求直接落到DB。
解决方案：
① 针对不同的key设置不同的过期时间。在KEY过期时间中加入随机数，防止同一时间大量数据过期现象发生
② 使用双缓存机制。缓存A设置过期时间，缓存B不设置过期时间。自己做缓存预热和更新。
  从缓存A读取数据，没有则从缓存B读取数据，直接返回。并启动异步线程更新缓存，同时更新A\B缓存。
③ 使用分布式锁。但会降低吞吐量
④ 设置热点KEY永不过期

架构层面：
事前：保证redis高可用，避免全盘宕机。(主从+哨兵，Cluster，持久化RDB\AOF)
事中：本地缓存+限流降级，避免Mysql被打死。(ehcache+Hystrix)
事后：使用RDB\AOF文件快速恢复缓存数据。
```

> 参考文档

[缓存穿透、缓存击穿、缓存雪崩区别和解决方案](https://blog.csdn.net/kongtiao5/article/details/82771694)

> ★★★ 问题总结的到位

[Redis使用总结（一、几点使用心得）](https://blog.csdn.net/hukaijun/article/details/81010279)

[Redis系列(二十)、缓存穿透、击穿、雪崩、预热、更新、降级](https://blog.csdn.net/wsdc0521/article/details/106907436)

[Redis缓存雪崩，缓存穿透，热点key解决方案和分析](https://www.cnblogs.com/wffzk/p/11842195.html)

[缓存雪崩、缓存穿透、缓存预热、缓存更新、缓存降级](https://www.cnblogs.com/leeSmall/p/8594542.html)

> 文档写的很不错
[Redis系列(二十)、缓存穿透、击穿、雪崩、预热、更新、降级](https://blog.csdn.net/wsdc0521/article/details/106907436)


### 七、缓存预热
> 系统上线时，若缓存中没有数据。会导致所有请求都打到数据库上。并发量大很有可能导致宕机

```markdown
缓存预热方案：
① 数据量不大时，可以在项目启动时。进行自动加载
② 定时任务去加载缓存
③ 可以通过页面调用API手动加载缓存
```

-----

### 八、Redis并发竞争KEY的问题
> 线上环境有可能会存在多个客户端并发写一个KEY，会导致数据版本错误，或者顺序错误。

```markdown
解决方案： 
1. 如果对KEY的操作，不要求有顺序：则使用分布式锁，抢到锁的执行更新KEY操作。
2. 如果对KEY的操作，要求有顺序。则在保存数据库的时候，需要保存一个时间戳，在抢到锁执行更新KEY时，判断当前时间戳是否晚于缓存中KEY的时间戳，否则不做更新。

```

-----


### 九、Redis持久化机制 RDB+AOF
> RDB: redis DataBase  AOF: applend Only File
  持久化主要是做：灾难恢复、数据恢复。在主从架构中也做数据同步
  
```markdown
1. RDB 在指定的时间间隔内把数据以快照的形式保存到磁盘上。
REDIS默认的持久化方式。默认文件名：dump.rdb。

2. RDB 触发机制?
D:
① save触发：执行save命令会触发执行RDB操作。但save命令执行期间会阻塞Redsi服务器，知道RDB执行完成。如果存在老的RDB文件则进行替换。
② bgsave触发，执行bgsave命令会在后台触发执行RDB操作。但不会阻塞Redis服务器，Redis可以正常响应客户端。
  具体：Redis进程执行fork操作创建子进程执行RDB操作，完成后自动结束。阻塞只发生在fork阶段，时间很短。
③ 配置文件配置(redis.conf)，自动触发
参数项
-------------------------------------------------------  
save   配置触发RDB持久化条件，即什么时候将内存中数据保存到磁盘。save m n :表示在m秒内存数据集存在n次修改时，则触发bgsave。
默认：
save 900 1       若900秒内至少有一个key值发生变化
save 300 10      若300秒内至少有10个key值发生变化
save 60  10000   若60秒内至少有10000个key值发生变化
-------------------------------------------------------    
stop-writes-on-bgsave-error  默认：yes 。当启用RDB后，最后一次保存数据失败时。Redis是否停止接受数据。如果停止接受数据，会让客户端意识到数据没有正确持久化到磁盘。
rdbcompression               默认：yes 。快照存储到磁盘中，可以设置是否进行压缩存储。
rdbchecksum                  默认：yes 。快照存储后，可以让redis采用CRC64算法来进行数据校验。但会增加约10%的性能开销。如果希望获得最大的性能，可以关闭此功能。
dbfilename                   设置快照的名称。默认：dump.rdb
dir                          设置快照文件的存放路径

3. RDB的优缺点：
优点：
① RDB文件紧凑，全量备份。非常适合进行备份和容灾恢复。(RDB会生成多个数据文件，每个数据文件都代表某一个时刻中redis的数据，非常适合做冷备)
② RDB在恢复大数据集时的速度比AOF速度快。
③ 生产RDB文件时，redis会fork一个子进行执行。主进程可以继续对外提供读写服务，保持高性能
缺点：
① RDB基于一定的时间间隔执行全量的快照备份(一般5分钟)，如果宕机丢失数据会比较多
② RDB是Redis通过fork()子进程来执行的，如果数据文件特别大。可能会导致对客户端提供服务暂停数毫秒、甚至秒


4. AOF: 基于append only模式，redis会把每次的写命令都通过write函数追加到aof文件中。
   aof文件记录的是每次写操作执行的命令，是可查阅的。但会随着写入时间变长文件越来越大。
   redis记录写命令到linux的os cache中，然后根据AOF触发机制执行fsync持久化到磁盘。
   
5. AOF触发机制？
D:
① always: 每次写操作都同步执行fsync操作，写入aof文件。性能差但数据完整性好
② everysec: 每秒记录一次。如果宕机会存在1秒的数据丢失。redis记录写命令
③ no: 从不同步

6. AOF的rewrite机制？
D:
Reids的AOF持久化机制会在aof文件很大的时候，进行rewrite操作。rewrite是基于当时内存中的数据进行指令的重新构建，健壮性会更好。
在创建新的文件时，老日志还会继续写入。当新的merge后的文件准备好后，替换老的日志。

7. AOF的优缺点：
优点：
① 如果宕机AOF机制丢失数据更少。配置持久化机制最多丢失1秒数据
② AOF写入文件没有任何磁盘寻址开销，写入性能非常高，文件不容易破损。
③ AOF即是文件过大的时候，也不会影响读性能。
④ AOF文件是可读的，非常适合做灾难性的误删操作的紧急恢复。
缺点：
① 对于同一份数据，AOF文件通常要比RDB文件更大。
② AOF每个1秒执行fsync刷盘一次日志。支持写的QPS会比RDB模式低，但也还是很高的
③ 通过AOF进行数据恢复有bug。

8. REDIS持久化机制如何选择？
D:
RDB 会周期性的持久化数据，配合安全的远程存储，非常适合冷备。但一旦宕机丢失数据会很多。
AOF AOF数据只有一份，做冷备要做额外的配置。且AOF通过重放指令来恢复数据没有RDB数据快。RDB通过快照方式生成的快照要比AOF这种复杂备份机制更加健壮bug少。

综合使用两种机制。用AOF来保证数据不丢失，和紧急性的灾难恢复。用RDB来做不同程度的冷备份，在AOF文件丢失或不可用时，用RDB来快速进行数据恢复。
同时配置两种机制，在Redis重启时，会使用AOF来重新构建数据，因为AOF的数据更加完整。

```
> 纤细介绍2种持久化机制

[详解Redis中两种持久化机制RDB和AOF](https://baijiahao.baidu.com/s?id=1654694618189745916&wfr=spider&for=pc)

-----


### 十、Redis分布式锁
> 在分布式或集群环境中，对共享资源的访问。保证同一时刻只能有一个线程去处理。就需要分布式锁来保证

```markdown
1. 分布式锁要满足的基本特性
① 互斥性：任意时刻，只能有一个客户端可以持有锁
② 安全性：只有加锁的客户端才能解锁，且只能解自己的锁
③ 防死锁：锁要设置过期时间，防止系统宕机造成死锁
④ 性能：  锁的颗粒度要尽量小，范围尽量要小。减少锁的等待时间
⑤ 重入：  同一个客户端线程可以多次获取同一把锁
⑥ 重试：  获取锁失败重试直到成功，或指定次数
⑦ 容错：  保障高可用

2. 分布式锁的实现方式
① 基于数据库实现
② 基于REDIS实现
③ 基于ZOOKEEPER实现


3. 基于REDIS实现分布式锁的方式
① Redis的客户端Jedis
② 官方推荐RedisLock
③ Reddission

Jedis实现：set.(key,value,nx,px) ;  续期和可重入要自己编写业务逻辑来保证 
Reddission实现：提供 自动续期 可重入 超时重试。没有解决。
RedisLock是实现：redis作者提供，但真实实践较少且算法本身还有争议。

RedisLock实现分布式锁的原理：
① 获取当前时间戳，单位毫秒
② 轮流尝试在每个master节点创建锁，使用相同的key和具有唯一性的value。过期时间设置较短，一般几十毫秒
③ 尝试在大多数节点上创建锁，如：5个节点则要求3是个节点(n/2+1)
④ 客户端计算好加锁时间，如果创建锁的时间小于超时时间，就算加锁成功
⑤ 如果超时，则加锁失败。依次删除这个锁
⑥ 只要别人加锁成功，其余客户端就不断轮询去尝试加锁


4. Reddisson实现分布式锁原理
①  线程一、线程二同时来进行加锁。线程一判断加锁的key是否存在，不存在。则执行lua脚本进行加锁。
②  这里存储锁的类型是Hash类型，Hash类型的key值包含了当前线程的信息。它的组成：guid+当前线程ID，value值。这里value值是可重入的关键
③  加锁时默认设置过期时间30s，可以通过API设置过期时间。同时后台开启定时任务，也就是watch dog线程，默认每隔10秒检查一下，如果当前线程还持有锁，则延长锁的时间
④  当线程二过来加锁时，判断锁是否存在，发现锁已经存在。则继续判断锁key值的hash数据中，是否包含线程二的ID，若不是。返回当前锁的剩余过期时间。
   此时线程二会进入while循环，不断尝试加锁
⑤  当线程一在过来加锁时，判断锁key值的hash数据结构中，包含了当前线程的ID，执行可重入加锁逻辑，value值加1
⑥  锁释放，每次执行lock.unlock()就对锁key值的数据结构中value值减1，当value=0时，说明已经没有线程持有锁了。此时执行del删除锁key，广播锁释放消息(通知阻塞线程)
⑦  客户端加锁成功后，默认锁的有效期是30s。一旦加锁成功后台就会启动一个watch dog线程，每隔10秒来检查一下，客户端还是否持有锁，如果持有则延长加锁时间。
   锁的过期时间可调用Lock的API来指定。watch dog线程后台检查时间，也可以通过config.setLockWatchdogTimeout(100)来指定
   

5. Redis实现分布式锁的问题：
> 高可用与续期问题

① 单实例无法保证高可用，主从哨兵机制存在异步复制问题。当在master加锁成功后，异步复制slave节点过程中，master宕机异步复制失败。
  slave成为新的master时，新的master没有锁。此时其他客户端同样也可以获取锁
  可以通过配置解决：把异步复制改为同步复制
  min-slave-to-write 1
  min-slave-max-lag  10
② 使用主从哨兵的集群架构实现的分布式锁，要自己实现锁延期的功能。
③ 
```



> 基于Redission实现分布式锁的API调用

[基于redission的分布式锁](https://blog.csdn.net/liuxiao723846/article/details/88131065)
> 基于Jedis单机实现锁和基于Redisson红锁实现API

[单机Redis实现分布式锁、Redission可重入锁、Redission红锁机制](https://blog.csdn.net/qq_35688140/article/details/103461115)
> 分布式锁的特性及要求

[基于Redis、Redission、ConcurrentHashMap实现企业级分布式锁](https://blog.csdn.net/amosjob/article/details/99681707)
[]()
[]()
[]()



### 十一、Redis的高可用机制
> redis replication -> 主从 -> 读写分离 -> 高可用机制

```markdown
1. 
```


### 十二、`Redis`客户端API
> `Jedis`\ `lettuce` \ `Redisson`

```markdown
现代系统的多核和异步，为了不断提高吞吐量，异步非阻塞线程大行其道。Netty框架就是异步非阻塞线程实现

基本概况：
1. Jedis是同步操作(一次请求redis数据完成释放连接后，才允许下一次连接)，所以需要连接池来使用Jedis方案。
2. Jedis是Redis的java客户端实现，其API比较底层且全面的实现了redis的命令，即只要熟悉redis的API就能熟练使用Jedis。
3. lettuce和redisson都是基于netty实现。
4. Reddisson中的API则进行了比较高的抽象，Reddisson的宗旨是促进使用者对Redis的关注分离，从而让使用者将精力放在集中处理业务上。

可伸缩性:
1. Jedis使用阻塞的IO，且方法都是同步调用，不支持异步。Jedis客户端实例不是线程安全的，所以需要通过线程池使用Jedis。
2. Redisson使用非阻塞IO和基于Netty框架的事件驱动的通信层，方法调用是异步的。Redisson的API是线程安全的。
3. Lettuce是基于Netty框架的事件驱动的通信层，其方法调用是异步的。Lettuce的API是线程安全的。
```

-----

###  十三、`Redis`大key
> - 所谓大key就是存储本身的key值空间太大，或者hash、list、set等存储中value值过多。
> - 由于Redis是单线程运行，如果一次操作的value很大会对整个redis的响应造成负面影响。

```markdown
1. 大key的风险
① 读写大key会导致超时严重，甚至阻塞服务
② 如果删除大key，DEL命令可能阻塞Redis服务进程数十秒。对应用程序和Redis集群可用性造成影响
③ 建议每个key不超过1M

2. 模拟业务场景并给出解决方案
① 业务场景：通过redis的hash方式来存储每一天的用户订单数，如：key=order_20200917,field=order_id,value=10。如果一天有上千万甚至上亿订单时，key后面的值是很多的。存储空间占用也很大，造成所谓的大key
② 解决方案：将大key进行分割。为了分割均匀可以对field进行hash并通过介数N取余，将余数加到key上面。这里介数我们取997
           则新key为：newKey=order_20200617_String.valueOf(Math.abs(order_id.hashCode() % 997)) 


```

[如何解决Redis大key问题](https://www.jianshu.com/p/50c0894c0a19)

[Redis大Key优化](https://blog.csdn.net/lavorange/article/details/83475960)

[Redis大key优化方案](https://my.oschina.net/u/1000241/blog/3020957)

-----


### 十四、`Redis`热点key
> 热点key：如大促活动中某一热点商品；或者生活中的热点事件、热点评论等都会产生热点key。

```markdown
1. 

2. 热点key的解决方案：
① 服务端缓存：将热点数据缓存至服务端的内存中
② 备份热点key: 将热点key+随机数，随机分配至Redis集群中的其它节点。这样访问热点key就不会全部命中到一台机器上了

3. 如何检测热点key
① 凭经验，进行预估；如提前知道了活动或大促，就可以提前进行备份或缓存。
② 客户端收集：在操作redis之前对数据进行统计
③ 抓包进行评估：redis使用TCP协议与客户端进行通信，通信协议采用的是RESP，所有能进行拦截包进行解析
④ 在proxy层，对每个redis请求进行收集上报
⑤ redis自带命令查询：Redis4.0版本提供了 redis-cli -hotkeys 命令可以找出热点key。
  使用redis自带命令时，要注意先把内存逐出策略设置为：allkeys-lfu 或 volatile-lfu
 
 
```

[关于Redis热点key的一些思考](https://segmentfault.com/a/1190000019745366?utm_source=tag-newest)



---

### 十五、`Redis`主从脑裂问题

```markdown
- Redis主从脑裂问题
  Redis主从脑裂问题是指：因为网络问题，导致Redis Master节点和Slave节点和Sentinel节点处于不同的网络分区，此时因为sentinel集群无法感知到master的存在，所有将slave节点提升为master节点。此时存在
  两个不同的master节点，就像一个大脑分裂成了两个。
  
  集群脑裂问题中：如果客户端还在基于原来的master节点继续写入数据，那么新的master节点将无法同步这些数据。当网络问题解决之后，sentinel集群将原来的master节点降为slave节点，此时在从新的master同步
  数据，将会造成大量数据丢失。
  
  
- 解决方案
  redis配置文件中，修改配置
  min-slaves-to-write 3  连接到master的最少slave数量
  min-slaves-max-lag 10  slave连接到master的最大延迟时间
  
  上面的配置要求：至少3个slave节点，且数据复制和同步的延迟不能超过10秒，否则master就拒绝写入请求。配置这两个参数后，如果集群发生脑裂原先的master节点接受到客户端写入的请求会拒绝。
  
  注意：较新版的redis.conf配置中参数变成如下
  min-replicas-to-wirte 3
  min-replicas-max-lag 10
  
  redis中异步复制情况下数据丢失问题，可以通过修改这两个参数来控制

```

[redis集群（主从）脑裂及解决方案](https://blog.csdn.net/LO_YUN/article/details/97131426)

---







